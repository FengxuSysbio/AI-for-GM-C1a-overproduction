{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba7a973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Configuration parameters\n",
    "DATA_PATH = \"Data.xlsx\" \n",
    "MODEL_PATHS = {\n",
    "    'qP': 'qP_final_model.h5',\n",
    "    'mu': 'mu_final_model.h5'\n",
    "}\n",
    "FEATURE_NAMES = ['OUR', 'CER', 'DO', 'pH', \n",
    "                'TS', 'RS', 'AN'] \n",
    "SAMPLE_INDEX = 42  # Index of samples selected for analysis\n",
    "N_BACKGROUND = 100  # SHAP background sample size\n",
    "\n",
    "# Data Preparation Functions\n",
    "def prepare_data(target):\n",
    "    # Load Raw Data\n",
    "    df = pd.read_excel(DATA_PATH)\n",
    "    X = df.iloc[:, :7].values\n",
    "    y = df[target].values\n",
    "    \n",
    "    # Data normalization (using previously saved scaler)\n",
    "    scaler_X = StandardScaler().fit(X)\n",
    "    X_scaled = scaler_X.transform(X)\n",
    "    \n",
    "    return X_scaled, scaler_X\n",
    "\n",
    "# SHAP Analysis Master Functions\n",
    "def shap_analysis(target):\n",
    "    print(f\"\\n=== Analysis in progress {target} model ===\")\n",
    "    \n",
    "    # Loading models and data\n",
    "    model = load_model(MODEL_PATHS[target])\n",
    "    X_scaled, scaler_X = prepare_data(target)\n",
    "    \n",
    "    # Preparation of background and test data\n",
    "    background = shap.utils.sample(X_scaled, N_BACKGROUND)\n",
    "    test_sample = X_scaled[SAMPLE_INDEX:SAMPLE_INDEX+1]\n",
    "    \n",
    "    # Creating an Interpreter\n",
    "    explainer = shap.DeepExplainer(\n",
    "        model,\n",
    "        background\n",
    "    )\n",
    "    \n",
    "    # Calculating the SHAP value\n",
    "    shap_values = explainer.shap_values(test_sample)\n",
    "    \n",
    "    # visualization and analysis\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    shap.summary_plot(\n",
    "        explainer.shap_values(background),\n",
    "        features=background,\n",
    "        feature_names=FEATURE_NAMES,\n",
    "        show=False\n",
    "    )\n",
    "    plt.title(f'{target} Model Feature Importance')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{target}_shap_summary.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Individual sample analysis\n",
    "    plt.figure()\n",
    "    shap.decision_plot(\n",
    "        explainer.expected_value.numpy(),\n",
    "        shap_values[0], \n",
    "        test_sample[0],\n",
    "        feature_names=FEATURE_NAMES,\n",
    "        show=False\n",
    "    )\n",
    "    plt.title(f'{target} Prediction Breakdown')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{target}_decision_plot.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Generate dependency graphs\n",
    "    for feat_idx in range(7):\n",
    "        plt.figure()\n",
    "        shap.dependence_plot(\n",
    "            feat_idx,\n",
    "            explainer.shap_values(background)[0],\n",
    "            features=background,\n",
    "            feature_names=FEATURE_NAMES,\n",
    "            show=False\n",
    "        )\n",
    "        plt.title(f'{target} Feature {FEATURE_NAMES[feat_idx]} Dependency')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{target}_dep_{FEATURE_NAMES[feat_idx]}.png')\n",
    "        plt.close()\n",
    "    \n",
    "    # Save SHAP value data\n",
    "    np.savez(f'{target}_shap_values.npz',\n",
    "            shap_values=shap_values,\n",
    "            sample_values=test_sample,\n",
    "            feature_names=FEATURE_NAMES)\n",
    "    \n",
    "    print(f\"{target} Analysis complete, results saved\")\n",
    "\n",
    "# Interactive Visualization Functions\n",
    "def interactive_shap_analysis(target):\n",
    "    # Load data\n",
    "    X_scaled, _ = prepare_data(target)\n",
    "    model = load_model(MODEL_PATHS[target])\n",
    "    \n",
    "    # Creating JS Visualizations\n",
    "    explainer = shap.DeepExplainer(model, X_scaled[:N_BACKGROUND])\n",
    "    shap_values = explainer.shap_values(X_scaled[:10])\n",
    "    \n",
    "    # Generate interactive visualizations\n",
    "    shap.initjs()\n",
    "    force_plot = shap.force_plot(\n",
    "        explainer.expected_value.numpy(),\n",
    "        shap_values[0][0], \n",
    "        X_scaled[0],\n",
    "        feature_names=FEATURE_NAMES\n",
    "    )\n",
    "    shap_html = f\"<head>{shap.getjs()}</head>{force_plot.html()}\"\n",
    "    \n",
    "    with open(f'{target}_interactive_shap.html', 'w') as f:\n",
    "        f.write(shap_html)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Implementation of the core analysis\n",
    "    for target in ['qP', 'mu']:\n",
    "        shap_analysis(target)\n",
    "    \n",
    "    # Generate interactive visualizations\n",
    "    interactive_shap_analysis('qP')\n",
    "    interactive_shap_analysis('mu')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
